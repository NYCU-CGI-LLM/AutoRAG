node_lines:
- node_line_name: retrieve_node_line
  nodes:
  - modules:
    - module_type: HybridRRF
      target_module_params:
      - top_k: 3
      - top_k: 3
      target_modules:
      - VectorDB
      - BM25
      top_k: 3
      weight: 4.0
    node_type: retrieval
    strategy:
      metrics:
      - retrieval_f1
      - retrieval_recall
      - retrieval_ndcg
      - retrieval_mrr
- node_line_name: post_retrieve_node_line
  nodes:
  - modules:
    - module_type: Fstring
      prompt: "Read the passages and answer the given question. \n Question: {query}\
        \ \n Passage: {retrieved_contents} \n Answer : "
    node_type: prompt_maker
    strategy:
      metrics:
      - metric_name: meteor
      - metric_name: rouge
      - embedding_model: openai
        metric_name: sem_score
  - modules:
    - batch: 16
      llm: gpt-4o-mini
      module_type: OpenAILLM
    node_type: generator
    strategy:
      metrics:
      - metric_name: meteor
      - metric_name: rouge
      - embedding_model: openai
        metric_name: sem_score
vectordb:
- client_type: persistent
  collection_name: openai
  db_type: chroma
  embedding_model: openai
  name: default
  path: /mnt/nfs/work/david97099/Github/deploy_autorag/content/project_dir/resources/chroma
