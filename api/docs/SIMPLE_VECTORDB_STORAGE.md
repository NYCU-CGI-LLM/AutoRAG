# Simple Vector Database Storage Strategy

## ğŸ¯ æ¶æ„æ¦‚è¿°

åŸºäºå½“å‰éœ€æ±‚ï¼Œé‡‡ç”¨ç®€åŒ–çš„å•å±‚å­˜å‚¨æ¶æ„ï¼š**ChromaDB + PostgreSQL**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ç®€åŒ–å­˜å‚¨æ¶æ„                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŒ¡ï¸ ChromaDB (Vector Storage)                               â”‚
â”‚    â€¢ å­˜å‚¨: embeddingå‘é‡ + doc_id + metadata                â”‚
â”‚    â€¢ ç”¨é€”: ç›¸ä¼¼æ€§æœç´¢ã€è¯­ä¹‰æ£€ç´¢                               â”‚
â”‚    â€¢ ä½ç½®: ./resources/chroma/                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“Š PostgreSQL (Metadata Management)                        â”‚
â”‚    â€¢ å­˜å‚¨: æ–‡æ¡£å…³ç³»ã€ç´¢å¼•é…ç½®ã€ç»Ÿè®¡ä¿¡æ¯                        â”‚
â”‚    â€¢ ç”¨é€”: ç®¡ç†embeddingä¸ä¸šåŠ¡æ•°æ®çš„å…³è”                       â”‚
â”‚    â€¢ ä¸å­˜å‚¨: å®é™…çš„embeddingå‘é‡                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—„ï¸ ChromaDBå­˜å‚¨è®¾è®¡

### 1. Collectionå‘½åç­–ç•¥

```python
# æŒ‰ä¸šåŠ¡å’Œæ¨¡å‹åˆ†ç»„
collection_name = f"{library_id}_{embedding_model}"

# ç¤ºä¾‹
"library_123_openai_embed_3_large"
"library_456_openai_embed_3_large" 
"library_123_bge_m3"
```

### 2. æ•°æ®å­˜å‚¨æ ¼å¼

```python
# ChromaDBä¸­çš„æ•°æ®ç»“æ„
{
    "ids": ["doc_uuid_1", "doc_uuid_2", ...],
    "embeddings": [[0.1, 0.2, ...], [0.3, 0.4, ...], ...],
    "metadatas": [
        {
            "doc_id": "doc_uuid_1",
            "library_id": "library_123", 
            "chunk_index": 0,
            "content_hash": "sha256_hash",
            "embedding_model": "openai_embed_3_large",
            "created_at": "2024-01-01T12:00:00Z",
            "content_preview": "This is the first 100 chars..."  # ä¾¿äºè°ƒè¯•
        },
        ...
    ],
    "documents": [
        "å®Œæ•´çš„æ–‡æ¡£å†…å®¹...",  # å¯é€‰ï¼šå­˜å‚¨åŸæ–‡ä¾¿äºæ£€ç´¢
        ...
    ]
}
```

### 3. é…ç½®æ–‡ä»¶

```yaml
# config/vectordb.yaml
vectordb:
  - name: api_chroma
    db_type: chroma
    client_type: persistent
    embedding_model: openai_embed_3_large
    collection_name: "{library_id}_{embedding_model}"  # åŠ¨æ€ç”Ÿæˆ
    path: ${PROJECT_DIR}/resources/chroma
    similarity_metric: cosine
    embedding_batch: 100
```

## ğŸ”— ä¸PostgreSQLçš„å…³è”

### 1. æ•°æ®åº“è¡¨è®¾è®¡

```sql
-- æ‰©å±•ç°æœ‰çš„indexerè¡¨ï¼Œæ·»åŠ vectorç›¸å…³å­—æ®µ
ALTER TABLE indexer ADD COLUMN IF NOT EXISTS collection_name VARCHAR(255);
ALTER TABLE indexer ADD COLUMN IF NOT EXISTS vector_dimension INTEGER;
ALTER TABLE indexer ADD COLUMN IF NOT EXISTS total_vectors INTEGER DEFAULT 0;

-- åˆ›å»ºembeddingç»Ÿè®¡è¡¨
CREATE TABLE IF NOT EXISTS embedding_stats (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    library_id UUID NOT NULL REFERENCES library(id) ON DELETE CASCADE,
    indexer_id UUID NOT NULL REFERENCES indexer(id) ON DELETE CASCADE,
    collection_name VARCHAR(255) NOT NULL,
    embedding_model VARCHAR(255) NOT NULL,
    total_documents INTEGER DEFAULT 0,
    vector_dimension INTEGER NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    
    UNIQUE(library_id, indexer_id)
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_embedding_stats_library ON embedding_stats(library_id);
CREATE INDEX IF NOT EXISTS idx_embedding_stats_collection ON embedding_stats(collection_name);
```

### 2. å…³è”å…³ç³»

```python
# æ•°æ®æµå‘
1. ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£ â†’ Fileè¡¨
2. è§£ææ–‡æ¡£ â†’ FileParseResultè¡¨  
3. åˆ†å—å¤„ç† â†’ FileChunkResultè¡¨
4. åˆ›å»ºembedding â†’ ChromaDB + embedding_statsè¡¨
5. æ£€ç´¢æŸ¥è¯¢ â†’ ChromaDBæœç´¢ + PostgreSQLå…³è”
```

## ğŸš€ APIå®ç°

### 1. å­˜å‚¨Embedding

```python
class VectorDBService:
    def __init__(self):
        self.chroma_client = self._init_chroma()
    
    def store_embeddings(
        self,
        library_id: UUID,
        doc_ids: List[str],
        contents: List[str],
        embedding_model: str = "openai_embed_3_large"
    ) -> Dict[str, Any]:
        """å­˜å‚¨embeddingåˆ°ChromaDB"""
        
        # 1. ç”Ÿæˆcollectionåç§°
        collection_name = f"lib_{library_id}_{embedding_model}"
        
        # 2. è·å–æˆ–åˆ›å»ºcollection
        collection = self.chroma_client.get_or_create_collection(
            name=collection_name,
            metadata={"hnsw:space": "cosine"}
        )
        
        # 3. å‡†å¤‡metadata
        metadatas = []
        for i, (doc_id, content) in enumerate(zip(doc_ids, contents)):
            metadatas.append({
                "doc_id": doc_id,
                "library_id": str(library_id),
                "chunk_index": i,
                "embedding_model": embedding_model,
                "created_at": datetime.utcnow().isoformat(),
                "content_preview": content[:100] + "..." if len(content) > 100 else content
            })
        
        # 4. æ·»åŠ åˆ°ChromaDB (è‡ªåŠ¨ç”Ÿæˆembedding)
        collection.add(
            ids=doc_ids,
            documents=contents,  # ChromaDBä¼šè‡ªåŠ¨ç”Ÿæˆembedding
            metadatas=metadatas
        )
        
        # 5. æ›´æ–°PostgreSQLç»Ÿè®¡
        self._update_embedding_stats(
            library_id, collection_name, embedding_model, len(doc_ids)
        )
        
        return {
            "collection_name": collection_name,
            "total_documents": len(doc_ids),
            "embedding_model": embedding_model
        }
```

### 2. ç›¸ä¼¼æ€§æœç´¢

```python
def similarity_search(
    self,
    library_id: UUID,
    query: str,
    top_k: int = 10,
    embedding_model: str = "openai_embed_3_large",
    filters: Optional[Dict] = None
) -> List[Dict[str, Any]]:
    """åœ¨æŒ‡å®šlibraryä¸­æœç´¢ç›¸ä¼¼æ–‡æ¡£"""
    
    # 1. æ„å»ºcollectionåç§°
    collection_name = f"lib_{library_id}_{embedding_model}"
    
    # 2. è·å–collection
    try:
        collection = self.chroma_client.get_collection(collection_name)
    except Exception:
        return []  # Collectionä¸å­˜åœ¨
    
    # 3. æ„å»ºæŸ¥è¯¢è¿‡æ»¤å™¨
    where_filter = {"library_id": str(library_id)}
    if filters:
        where_filter.update(filters)
    
    # 4. æ‰§è¡Œæœç´¢
    results = collection.query(
        query_texts=[query],
        n_results=top_k,
        where=where_filter,
        include=["documents", "metadatas", "distances"]
    )
    
    # 5. æ ¼å¼åŒ–ç»“æœ
    search_results = []
    for i in range(len(results["ids"][0])):
        search_results.append({
            "doc_id": results["ids"][0][i],
            "content": results["documents"][0][i],
            "metadata": results["metadatas"][0][i],
            "score": 1 - results["distances"][0][i],  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
            "rank": i + 1
        })
    
    return search_results
```

### 3. ç®¡ç†API

```python
@router.get("/v1/library/{library_id}/embeddings/stats")
async def get_embedding_stats(
    library_id: UUID,
    session: Session = Depends(get_session)
):
    """è·å–libraryçš„embeddingç»Ÿè®¡ä¿¡æ¯"""
    
    stats = session.exec(
        select(EmbeddingStats).where(EmbeddingStats.library_id == library_id)
    ).all()
    
    return {
        "library_id": library_id,
        "collections": [
            {
                "collection_name": stat.collection_name,
                "embedding_model": stat.embedding_model,
                "total_documents": stat.total_documents,
                "vector_dimension": stat.vector_dimension,
                "created_at": stat.created_at
            }
            for stat in stats
        ]
    }

@router.post("/v1/library/{library_id}/embeddings/search")
async def search_embeddings(
    library_id: UUID,
    request: SearchRequest,
    vectordb_service: VectorDBService = Depends()
):
    """åœ¨libraryä¸­æœç´¢ç›¸ä¼¼æ–‡æ¡£"""
    
    results = vectordb_service.similarity_search(
        library_id=library_id,
        query=request.query,
        top_k=request.top_k,
        embedding_model=request.embedding_model,
        filters=request.filters
    )
    
    return {
        "query": request.query,
        "library_id": library_id,
        "total_results": len(results),
        "results": results
    }
```

## ğŸ“ æ–‡ä»¶ç»„ç»‡ç»“æ„

```
api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ vectordb_service.py      # ChromaDBæ“ä½œæœåŠ¡
â”‚   â”‚   â””â”€â”€ embedding_service.py     # Embeddingç®¡ç†æœåŠ¡
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ embedding_stats.py       # Embeddingç»Ÿè®¡æ¨¡å‹
â”‚   â””â”€â”€ routers/
â”‚       â””â”€â”€ embeddings.py            # Embeddingç›¸å…³API
â”œâ”€â”€ config/
â”‚   â””â”€â”€ vectordb.yaml               # ChromaDBé…ç½®
â””â”€â”€ resources/
    â””â”€â”€ chroma/                      # ChromaDBæ•°æ®å­˜å‚¨ç›®å½•
        â”œâ”€â”€ lib_123_openai_embed_3_large/
        â”œâ”€â”€ lib_456_openai_embed_3_large/
        â””â”€â”€ ...
```

## ğŸ”§ é…ç½®ç¤ºä¾‹

```python
# app/core/config.py
class Settings(BaseSettings):
    # ... existing settings ...
    
    # ChromaDB Configuration
    chroma_path: str = Field("./resources/chroma", env="CHROMA_PATH")
    default_embedding_model: str = Field("openai_embed_3_large", env="DEFAULT_EMBEDDING_MODEL")
    embedding_batch_size: int = Field(100, env="EMBEDDING_BATCH_SIZE")
```

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### 1. Collectionç®¡ç†ç­–ç•¥

```python
# æŒ‰libraryåˆ†ç¦»ï¼Œé¿å…æ•°æ®æ··æ·†
collection_name = f"lib_{library_id}_{embedding_model}"

# ä¼˜åŠ¿ï¼š
- æ•°æ®éš”ç¦»ï¼šä¸åŒlibraryçš„æ•°æ®å®Œå…¨åˆ†ç¦»
- æƒé™æ§åˆ¶ï¼šå¯ä»¥åŸºäºlibrary_idæ§åˆ¶è®¿é—®
- æ€§èƒ½ä¼˜åŒ–ï¼šæœç´¢èŒƒå›´é™å®šåœ¨ç‰¹å®šlibrary
- æ˜“äºç®¡ç†ï¼šå¯ä»¥ç‹¬ç«‹åˆ é™¤æŸä¸ªlibraryçš„æ‰€æœ‰embedding
```

### 2. æ€§èƒ½ä¼˜åŒ–

```python
# æ‰¹é‡æ“ä½œ
def batch_add_embeddings(doc_ids: List[str], contents: List[str], batch_size: int = 100):
    for i in range(0, len(doc_ids), batch_size):
        batch_ids = doc_ids[i:i+batch_size]
        batch_contents = contents[i:i+batch_size]
        collection.add(ids=batch_ids, documents=batch_contents)

# å¼‚æ­¥å¤„ç†å¤§é‡æ•°æ®
async def async_embedding_creation(library_id: UUID, file_chunks: List[Dict]):
    # åå°ä»»åŠ¡å¤„ç†å¤§é‡embeddingåˆ›å»º
    pass
```

### 3. ç›‘æ§å’Œç»´æŠ¤

```python
# å®šæœŸæ¸…ç†å’Œä¼˜åŒ–
def maintenance_tasks():
    # 1. æ¸…ç†å­¤ç«‹çš„collection
    # 2. å‹ç¼©æ•°æ®åº“
    # 3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    # 4. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
    pass
```

## ğŸ“ˆ æ‰©å±•è€ƒè™‘

å½“æ•°æ®é‡å¢é•¿æ—¶ï¼Œå¯ä»¥è€ƒè™‘ï¼š

1. **æ°´å¹³åˆ†ç‰‡** - æŒ‰æ—¶é—´æˆ–hashåˆ†å‰²collection
2. **è¯»å†™åˆ†ç¦»** - ä½¿ç”¨å¤šä¸ªChromaDBå®ä¾‹
3. **å‡çº§åˆ°Qdrant** - æ›´å¥½çš„æ€§èƒ½å’Œé›†ç¾¤æ”¯æŒ
4. **æ·»åŠ ç¼“å­˜å±‚** - Redisç¼“å­˜çƒ­é—¨æŸ¥è¯¢ç»“æœ

ä½†ç›®å‰çš„ç®€åŒ–æ¶æ„è¶³ä»¥æ”¯æ’‘å¤§å¤šæ•°APIæœåŠ¡çš„éœ€æ±‚ã€‚ 